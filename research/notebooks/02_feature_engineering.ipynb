{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BNPL Feature Engineering\n",
    "\n",
    "**Objective**: Create domain-specific features for BNPL risk prediction\n",
    "\n",
    "**Feature Categories**:\n",
    "1. **Payment Velocity**: Speed and consistency of payments\n",
    "2. **Risk Indicators**: Historical default patterns and red flags\n",
    "3. **Customer Profile**: Demographic and behavioral features\n",
    "4. **Transaction Patterns**: Spending behavior and trends\n",
    "5. **Temporal Features**: Time-based patterns and seasonality\n",
    "\n",
    "**Business Context**: BNPL decisions need to be made in <100ms with high accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# BigQuery integration\n",
    "from google.cloud import bigquery\n",
    "from flit_ml.config import config\n",
    "\n",
    "# Configuration\n",
    "pd.set_option('display.max_columns', 50)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(\"Feature engineering environment ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading Strategy\n",
    "\n",
    "For feature engineering, we need customer-level aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to BigQuery\n",
    "client = config.get_client()\n",
    "\n",
    "# Load larger sample for feature engineering (stratified by customer)\n",
    "feature_data_query = \"\"\"\n",
    "WITH customer_sample AS (\n",
    "  SELECT DISTINCT customer_id\n",
    "  FROM `flit-data-platform.flit_staging.stg_bnpl_raw_transactions`\n",
    "  ORDER BY RAND()\n",
    "  LIMIT 5000  -- Sample customers for faster iteration\n",
    ")\n",
    "SELECT t.*\n",
    "FROM `flit-data-platform.flit_staging.stg_bnpl_raw_transactions` t\n",
    "INNER JOIN customer_sample cs ON t.customer_id = cs.customer_id\n",
    "ORDER BY t.customer_id, t.transaction_date\n",
    "\"\"\"\n",
    "\n",
    "print(\"üì• Loading customer transaction data...\")\n",
    "df = client.query(feature_data_query).to_dataframe()\n",
    "\n",
    "print(f\"Data loaded: {df.shape[0]:,} transactions for {df['customer_id'].nunique():,} customers\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Payment Velocity Features\n",
    "\n",
    "Key insight: Payment speed and consistency are strong predictors of default risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_payment_velocity_features(df):\n",
    "    \"\"\"\n",
    "    Calculate payment velocity and consistency features.\n",
    "    \n",
    "    Business Logic:\n",
    "    - Faster payers = lower default risk\n",
    "    - Consistent payment patterns = lower risk\n",
    "    - Late payment history = red flag\n",
    "    \"\"\"\n",
    "    # Ensure datetime conversion\n",
    "    df['transaction_date'] = pd.to_datetime(df['transaction_date'])\n",
    "    df['payment_due_date'] = pd.to_datetime(df['payment_due_date'])\n",
    "    \n",
    "    # Calculate days to payment\n",
    "    df['days_to_payment'] = (df['payment_date'] - df['transaction_date']).dt.days\n",
    "    df['days_early_late'] = (df['payment_due_date'] - df['payment_date']).dt.days\n",
    "    \n",
    "    # Customer-level aggregations\n",
    "    velocity_features = df.groupby('customer_id').agg({\n",
    "        'days_to_payment': ['mean', 'std', 'min', 'max'],\n",
    "        'days_early_late': ['mean', 'std'],\n",
    "        'transaction_amount': ['count', 'mean', 'std', 'sum'],\n",
    "        'payment_status': lambda x: (x == 'late').sum(),  # Count late payments\n",
    "    }).round(2)\n",
    "    \n",
    "    # Flatten column names\n",
    "    velocity_features.columns = [f\"velocity_{col[0]}_{col[1]}\" for col in velocity_features.columns]\n",
    "    \n",
    "    # Calculate derived features\n",
    "    velocity_features['velocity_late_payment_rate'] = (\n",
    "        velocity_features['velocity_payment_status_<lambda>'] / \n",
    "        velocity_features['velocity_transaction_amount_count']\n",
    "    ).round(3)\n",
    "    \n",
    "    velocity_features['velocity_payment_consistency'] = (\n",
    "        1 / (1 + velocity_features['velocity_days_to_payment_std'])\n",
    "    ).round(3)\n",
    "    \n",
    "    return velocity_features\n",
    "\n",
    "# Calculate velocity features\n",
    "print(\"‚ö° Calculating payment velocity features...\")\n",
    "# velocity_features = calculate_payment_velocity_features(df)\n",
    "# print(f\"Velocity features created: {velocity_features.shape}\")\n",
    "# velocity_features.head()\n",
    "\n",
    "# Note: This is a template - actual implementation depends on available columns\n",
    "print(\"üìù Velocity feature template created (awaiting actual schema)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Risk Indicator Features\n",
    "\n",
    "Features that historically correlate with default risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_risk_indicator_features(df):\n",
    "    \"\"\"\n",
    "    Calculate risk indicators based on BNPL domain knowledge.\n",
    "    \n",
    "    Risk Factors:\n",
    "    - High transaction amounts relative to income\n",
    "    - Frequent BNPL usage (over-borrowing)\n",
    "    - Declining payment performance\n",
    "    - Multiple failed payments\n",
    "    \"\"\"\n",
    "    \n",
    "    customer_risk = df.groupby('customer_id').agg({\n",
    "        'transaction_amount': ['sum', 'mean', 'max', 'count'],\n",
    "        'credit_score': 'first',  # Assume this exists\n",
    "        'annual_income': 'first',  # Assume this exists\n",
    "        'failed_payment_count': 'sum',  # Historical failures\n",
    "        'days_since_last_transaction': 'min',  # Recency\n",
    "    })\n",
    "    \n",
    "    # Flatten columns\n",
    "    customer_risk.columns = [f\"risk_{col[0]}_{col[1]}\" for col in customer_risk.columns]\n",
    "    \n",
    "    # Calculate derived risk indicators\n",
    "    customer_risk['risk_debt_to_income_ratio'] = (\n",
    "        customer_risk['risk_transaction_amount_sum'] / \n",
    "        customer_risk['risk_annual_income_first']\n",
    "    ).clip(0, 1).round(3)\n",
    "    \n",
    "    customer_risk['risk_transaction_frequency'] = (\n",
    "        customer_risk['risk_transaction_amount_count'] / 30  # Transactions per month\n",
    "    ).round(2)\n",
    "    \n",
    "    customer_risk['risk_avg_transaction_to_income'] = (\n",
    "        customer_risk['risk_transaction_amount_mean'] / \n",
    "        (customer_risk['risk_annual_income_first'] / 12)  # Monthly income\n",
    "    ).round(3)\n",
    "    \n",
    "    return customer_risk\n",
    "\n",
    "print(\"üö® Risk indicator feature template created\")\n",
    "print(\"Will implement after schema exploration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Temporal Features\n",
    "\n",
    "Time-based patterns that influence BNPL behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_temporal_features(df):\n",
    "    \"\"\"\n",
    "    Extract temporal patterns from transaction data.\n",
    "    \n",
    "    Temporal Insights:\n",
    "    - Weekend vs weekday spending patterns\n",
    "    - Month-end vs month-start behavior\n",
    "    - Seasonal spending (holidays, back-to-school)\n",
    "    - Time of day preferences\n",
    "    \"\"\"\n",
    "    \n",
    "    df['transaction_date'] = pd.to_datetime(df['transaction_date'])\n",
    "    \n",
    "    # Extract temporal components\n",
    "    df['day_of_week'] = df['transaction_date'].dt.dayofweek\n",
    "    df['day_of_month'] = df['transaction_date'].dt.day\n",
    "    df['month'] = df['transaction_date'].dt.month\n",
    "    df['quarter'] = df['transaction_date'].dt.quarter\n",
    "    df['hour'] = df['transaction_date'].dt.hour\n",
    "    \n",
    "    # Create categorical features\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    df['is_month_end'] = (df['day_of_month'] > 25).astype(int)\n",
    "    df['is_holiday_season'] = df['month'].isin([11, 12]).astype(int)\n",
    "    df['is_business_hours'] = df['hour'].between(9, 17).astype(int)\n",
    "    \n",
    "    # Customer temporal preferences\n",
    "    temporal_features = df.groupby('customer_id').agg({\n",
    "        'is_weekend': 'mean',\n",
    "        'is_month_end': 'mean', \n",
    "        'is_holiday_season': 'mean',\n",
    "        'is_business_hours': 'mean',\n",
    "        'day_of_week': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 0,\n",
    "        'hour': ['mean', 'std']\n",
    "    }).round(3)\n",
    "    \n",
    "    temporal_features.columns = [f\"temporal_{col[0]}_{col[1]}\" if isinstance(col, tuple) else f\"temporal_{col}\" for col in temporal_features.columns]\n",
    "    \n",
    "    return temporal_features\n",
    "\n",
    "print(\"‚è∞ Temporal feature engineering template ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering Pipeline\n",
    "\n",
    "Combine all feature engineering into a reproducible pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bnpl_features(df):\n",
    "    \"\"\"\n",
    "    Master feature engineering pipeline for BNPL risk prediction.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with engineered features at customer level\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üîß Starting feature engineering pipeline...\")\n",
    "    \n",
    "    # 1. Basic customer statistics\n",
    "    basic_features = df.groupby('customer_id').agg({\n",
    "        'transaction_amount': ['count', 'sum', 'mean', 'std', 'min', 'max'],\n",
    "        'customer_age': 'first',\n",
    "        'credit_score': 'first',\n",
    "        'annual_income': 'first'\n",
    "    })\n",
    "    \n",
    "    basic_features.columns = [f\"basic_{col[0]}_{col[1]}\" if isinstance(col, tuple) else f\"basic_{col}\" for col in basic_features.columns]\n",
    "    \n",
    "    # 2. Payment velocity features\n",
    "    # velocity_features = calculate_payment_velocity_features(df)\n",
    "    \n",
    "    # 3. Risk indicators\n",
    "    # risk_features = calculate_risk_indicator_features(df)\n",
    "    \n",
    "    # 4. Temporal patterns\n",
    "    temporal_features = calculate_temporal_features(df)\n",
    "    \n",
    "    # 5. Combine all features\n",
    "    # feature_df = pd.concat([\n",
    "    #     basic_features,\n",
    "    #     velocity_features,\n",
    "    #     risk_features,\n",
    "    #     temporal_features\n",
    "    # ], axis=1)\n",
    "    \n",
    "    # For now, just return basic + temporal\n",
    "    feature_df = pd.concat([basic_features, temporal_features], axis=1)\n",
    "    \n",
    "    print(f\"‚úÖ Feature engineering complete: {feature_df.shape}\")\n",
    "    return feature_df\n",
    "\n",
    "# This will be implemented once we understand the actual schema\n",
    "print(\"üèóÔ∏è  Feature engineering pipeline framework ready\")\n",
    "print(\"Next: Explore actual data schema to implement concrete features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Validation Framework\n",
    "\n",
    "Ensure features are predictive and production-ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_features(feature_df, target_col='default_risk'):\n",
    "    \"\"\"\n",
    "    Validate engineered features for production readiness.\n",
    "    \n",
    "    Validation Checks:\n",
    "    1. No missing values in critical features\n",
    "    2. Reasonable feature distributions\n",
    "    3. Low correlation with identifiers\n",
    "    4. Predictive power assessment\n",
    "    \"\"\"\n",
    "    \n",
    "    validation_report = {}\n",
    "    \n",
    "    # 1. Missing values\n",
    "    missing_pct = (feature_df.isnull().sum() / len(feature_df) * 100).round(2)\n",
    "    validation_report['missing_values'] = missing_pct[missing_pct > 0].to_dict()\n",
    "    \n",
    "    # 2. Feature distributions\n",
    "    numeric_features = feature_df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    distribution_issues = []\n",
    "    for col in numeric_features:\n",
    "        if feature_df[col].std() == 0:\n",
    "            distribution_issues.append(f\"{col}: No variance\")\n",
    "        elif feature_df[col].skew() > 10:\n",
    "            distribution_issues.append(f\"{col}: Highly skewed ({feature_df[col].skew():.1f})\")\n",
    "    \n",
    "    validation_report['distribution_issues'] = distribution_issues\n",
    "    \n",
    "    # 3. Feature correlations (high correlation = potential multicollinearity)\n",
    "    corr_matrix = feature_df[numeric_features].corr().abs()\n",
    "    high_corr_pairs = []\n",
    "    \n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i+1, len(corr_matrix.columns)):\n",
    "            if corr_matrix.iloc[i, j] > 0.8:\n",
    "                high_corr_pairs.append({\n",
    "                    'feature1': corr_matrix.columns[i],\n",
    "                    'feature2': corr_matrix.columns[j],\n",
    "                    'correlation': round(corr_matrix.iloc[i, j], 3)\n",
    "                })\n",
    "    \n",
    "    validation_report['high_correlations'] = high_corr_pairs\n",
    "    \n",
    "    return validation_report\n",
    "\n",
    "print(\"‚úÖ Feature validation framework ready\")\n",
    "print(\"Will validate features once they are generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Next Steps\n",
    "\n",
    "**Immediate Actions**:\n",
    "1. Run data exploration notebook to understand actual schema\n",
    "2. Implement concrete feature engineering based on available columns\n",
    "3. Validate feature quality and predictive power\n",
    "4. Create target variable for supervised learning\n",
    "\n",
    "**Feature Engineering Priorities**:\n",
    "1. **Payment Velocity** - Core BNPL predictor\n",
    "2. **Debt-to-Income Ratios** - Financial health indicator  \n",
    "3. **Historical Payment Performance** - Past behavior predicts future\n",
    "4. **Transaction Patterns** - Behavioral fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering roadmap\n",
    "roadmap = {\n",
    "    'phase_1_basic': [\n",
    "        'transaction_count_per_customer',\n",
    "        'avg_transaction_amount',\n",
    "        'total_exposure',\n",
    "        'customer_age',\n",
    "        'credit_score'\n",
    "    ],\n",
    "    'phase_2_velocity': [\n",
    "        'avg_days_to_payment',\n",
    "        'payment_consistency_score',\n",
    "        'late_payment_rate',\n",
    "        'payment_amount_variance'\n",
    "    ],\n",
    "    'phase_3_risk': [\n",
    "        'debt_to_income_ratio',\n",
    "        'transaction_frequency_trend',\n",
    "        'failed_payment_count',\n",
    "        'credit_utilization'\n",
    "    ],\n",
    "    'phase_4_temporal': [\n",
    "        'weekend_spending_ratio',\n",
    "        'month_end_behavior',\n",
    "        'seasonal_patterns',\n",
    "        'time_of_day_preferences'\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"üó∫Ô∏è  Feature Engineering Roadmap:\")\n",
    "for phase, features in roadmap.items():\n",
    "    print(f\"\\n{phase.upper()}:\")\n",
    "    for feature in features:\n",
    "        print(f\"  - {feature}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}