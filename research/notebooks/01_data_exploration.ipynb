{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BNPL Data Exploration\n",
    "\n",
    "**Objective**: Comprehensive exploratory data analysis of BNPL staging data\n",
    "\n",
    "**Data Source**: `flit-data-platform.flit_staging.stg_bnpl_raw_transactions`\n",
    "- **Records**: ~1.9M transactions\n",
    "- **Fields**: 42 columns\n",
    "- **Time Range**: TBD\n",
    "\n",
    "**Research Questions**:\n",
    "1. What is the distribution of transaction amounts?\n",
    "2. How do customer demographics correlate with risk?\n",
    "3. What temporal patterns exist in BNPL usage?\n",
    "4. What are the key predictive features for default risk?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# BigQuery integration\n",
    "from google.cloud import bigquery\n",
    "from flit_ml.config import config\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Connection and Schema Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to BigQuery\n",
    "client = config.get_client()\n",
    "\n",
    "# Test connection with basic query\n",
    "test_query = \"\"\"\n",
    "SELECT COUNT(*) as total_records\n",
    "FROM `flit-data-platform.flit_staging.stg_bnpl_raw_transactions`\n",
    "\"\"\"\n",
    "\n",
    "result = client.query(test_query).result()\n",
    "for row in result:\n",
    "    print(f\"‚úÖ Connected to BigQuery: {row.total_records:,} total records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get table schema information\n",
    "schema_query = \"\"\"\n",
    "SELECT\n",
    "    column_name,\n",
    "    data_type,\n",
    "    is_nullable,\n",
    "    description\n",
    "FROM `flit-data-platform.flit_staging.INFORMATION_SCHEMA.COLUMNS`\n",
    "WHERE table_name = 'stg_bnpl_raw_transactions'\n",
    "ORDER BY ordinal_position\n",
    "\"\"\"\n",
    "\n",
    "schema_df = client.query(schema_query).to_dataframe()\n",
    "print(f\"üìä Schema: {len(schema_df)} columns\")\n",
    "schema_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sample Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sample records for initial inspection\n",
    "sample_query = \"\"\"\n",
    "SELECT *\n",
    "FROM `flit-data-platform.flit_staging.stg_bnpl_raw_transactions`\n",
    "ORDER BY RAND()\n",
    "LIMIT 1000\n",
    "\"\"\"\n",
    "\n",
    "# Load sample data\n",
    "print(\"üì• Loading sample data...\")\n",
    "sample_df = client.query(sample_query).to_dataframe()\n",
    "\n",
    "print(f\"Sample data shape: {sample_df.shape}\")\n",
    "print(f\"Memory usage: {sample_df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types and basic info\n",
    "print(\"üìã Data Types and Info:\")\n",
    "sample_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary for numeric columns\n",
    "print(\"üìà Statistical Summary:\")\n",
    "sample_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values analysis\n",
    "missing_stats = {\n",
    "    'column': sample_df.columns,\n",
    "    'missing_count': sample_df.isnull().sum(),\n",
    "    'missing_percent': (sample_df.isnull().sum() / len(sample_df) * 100).round(2),\n",
    "    'dtype': sample_df.dtypes\n",
    "}\n",
    "\n",
    "missing_df = pd.DataFrame(missing_stats)\n",
    "missing_df = missing_df[missing_df['missing_count'] > 0].sort_values('missing_percent', ascending=False)\n",
    "\n",
    "print(\"‚ùì Missing Values Analysis:\")\n",
    "if len(missing_df) > 0:\n",
    "    print(missing_df)\n",
    "else:\n",
    "    print(\"‚úÖ No missing values found in sample data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values count for potential categorical variables\n",
    "print(\"üè∑Ô∏è  Categorical Variables Analysis:\")\n",
    "\n",
    "categorical_analysis = []\n",
    "for col in sample_df.columns:\n",
    "    unique_count = sample_df[col].nunique()\n",
    "    unique_ratio = unique_count / len(sample_df)\n",
    "    \n",
    "    # Identify potential categorical variables\n",
    "    if unique_ratio < 0.1 and unique_count < 50:\n",
    "        categorical_analysis.append({\n",
    "            'column': col,\n",
    "            'unique_count': unique_count,\n",
    "            'unique_ratio': round(unique_ratio, 3),\n",
    "            'sample_values': list(sample_df[col].value_counts().head(5).index)\n",
    "        })\n",
    "\n",
    "if categorical_analysis:\n",
    "    cat_df = pd.DataFrame(categorical_analysis)\n",
    "    for _, row in cat_df.iterrows():\n",
    "        print(f\"{row['column']}: {row['unique_count']} unique values ({row['unique_ratio']*100:.1f}%)\")\n",
    "        print(f\"  Sample values: {row['sample_values']}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"No obvious categorical variables detected in sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Key Business Metrics Overview\n",
    "\n",
    "Understanding the business context of BNPL transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic business metrics from full dataset\n",
    "business_metrics_query = \"\"\"\n",
    "SELECT\n",
    "    COUNT(*) as total_transactions,\n",
    "    COUNT(DISTINCT customer_id) as unique_customers,\n",
    "    AVG(transaction_amount) as avg_transaction_amount,\n",
    "    STDDEV(transaction_amount) as std_transaction_amount,\n",
    "    MIN(transaction_amount) as min_transaction_amount,\n",
    "    MAX(transaction_amount) as max_transaction_amount,\n",
    "    PERCENTILE_CONT(transaction_amount, 0.25) OVER() as p25_transaction_amount,\n",
    "    PERCENTILE_CONT(transaction_amount, 0.5) OVER() as median_transaction_amount,\n",
    "    PERCENTILE_CONT(transaction_amount, 0.75) OVER() as p75_transaction_amount,\n",
    "    MIN(transaction_date) as earliest_transaction,\n",
    "    MAX(transaction_date) as latest_transaction\n",
    "FROM `flit-data-platform.flit_staging.stg_bnpl_raw_transactions`\n",
    "LIMIT 1\n",
    "\"\"\"\n",
    "\n",
    "print(\"üìä Business Metrics Overview:\")\n",
    "business_metrics = client.query(business_metrics_query).to_dataframe()\n",
    "business_metrics.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Next Steps for Deep Analysis\n",
    "\n",
    "Based on the initial exploration, identify key areas for detailed analysis:\n",
    "\n",
    "1. **Transaction Amount Distribution**: Understand spending patterns\n",
    "2. **Customer Segmentation**: Identify different customer behaviors\n",
    "3. **Temporal Patterns**: Seasonal and time-based trends\n",
    "4. **Risk Indicators**: Identify features correlated with defaults\n",
    "5. **Feature Engineering**: Create BNPL-specific features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save key insights for next notebook\n",
    "insights = {\n",
    "    'total_records': int(business_metrics['total_transactions'].iloc[0]),\n",
    "    'unique_customers': int(business_metrics['unique_customers'].iloc[0]),\n",
    "    'avg_transaction': float(business_metrics['avg_transaction_amount'].iloc[0]),\n",
    "    'date_range': {\n",
    "        'start': str(business_metrics['earliest_transaction'].iloc[0]),\n",
    "        'end': str(business_metrics['latest_transaction'].iloc[0])\n",
    "    },\n",
    "    'schema_columns': len(schema_df),\n",
    "    'sample_size': len(sample_df)\n",
    "}\n",
    "\n",
    "print(\"üíæ Key Insights Summary:\")\n",
    "for key, value in insights.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# TODO: Save insights to file for next notebooks\n",
    "# import json\n",
    "# with open('../reports/data_exploration_insights.json', 'w') as f:\n",
    "#     json.dump(insights, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}